{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CS1.1 HISTOGRAM ##\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "def display_histogram(data,  feature_name, title_name='default'):\n",
    "    plt.hist(data)\n",
    "    plt.ylabel(feature_name)\n",
    "    plt.xlabel('No. of patients')\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "    \n",
    "bunchobject = datasets.load_breast_cancer()\n",
    "feature_range = [0]\n",
    "data_subset = bunchobject.data[:,feature_range]\n",
    "feature_name = bunchobject.feature_names[feature_range]\n",
    "display_histogram(data_subset,feature_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CS1.2 SCATTER PLOT ##\n",
    "import numpy as np\n",
    "import matplotlib.mlab as mlab\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "def display_scatter(x,y, xlabel='x', ylabel='y',title_name ='default'):\n",
    "    plt.scatter(x,y)\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "x_index = 0\n",
    "y_index = 3\n",
    "x = bunchobject.data[:,x_index]\n",
    "y = bunchobject.data[:,y_index]\n",
    "x_label = bunchobject.feature_names[x_index]\n",
    "y_label = bunchobject.feature_names[y_index]\n",
    "display_scatter(x,y,x_label,y_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CS1.3 BAR ##\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets\n",
    "def display_bar_chart(positions, counts, names, title_name='default' ):\n",
    "    plt.bar(positions,counts)\n",
    "    plt.show()\n",
    "unique, counts = np.unique(bunchobject.target, return_counts = True)\n",
    "display_bar_chart(unique, counts, bunchobject.target_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CS2 5 NUMBER SUMMARY ##\n",
    "import numpy as np\n",
    "def five_number_summary(X):\n",
    "  ans = []\n",
    "  for i in range(len(X[0])):    \n",
    "    x = [col[i] for col in X]\n",
    "    dict_keys = ['minimum','first quartile','median','third quartile','maximum']\n",
    "    dict_values = [np.min(x),np.percentile(x,25),np.percentile(x,50),np.percentile(x,75),np.max(x)]\n",
    "    ans.append(dict(zip(dict_keys,dict_values)))\n",
    "  return ans  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CS3 NORMALIZE MIN-MAX ##\n",
    "#import sklearn.preprocessing as pp\n",
    "#normalize_minmax = lambda data: pp.minmax_scale(data)\n",
    "import numpy as np\n",
    "def normalize_minmax(data):\n",
    "    output = [[] for _ in range(len(data))]\n",
    "    for i in range(len(data[0])):\n",
    "        data_slice = data[:, i]\n",
    "        ptp = max(data_slice) - min(data_slice)         \n",
    "        minimum = min(data_slice)\n",
    "        for j, slice_element in enumerate(data_slice):\n",
    "            output[j].append((slice_element - minimum) / ptp)\n",
    "    return np.array(output)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CS4 KNN ##\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as pp\n",
    "\n",
    "normalize_minmax = lambda data: pp.minmax_scale(data)  \n",
    "\n",
    "def get_metrics(actual_targets, predicted_targets):\n",
    " c_matrix = confusion_matrix(actual_targets, predicted_targets)\n",
    " T_rec = np.sum(c_matrix)\n",
    " acc = np.trace(c_matrix)/T_rec\n",
    " sen = c_matrix[1][1]/np.sum(c_matrix[1])\n",
    " fp = c_matrix[0][1]/np.sum(c_matrix[0])\n",
    " dict_key = ['confusion matrix','total records','accuracy','sensitivity','false positive rate']\n",
    " dict_values = [c_matrix,T_rec,acc,sen,fp]\n",
    " return dict(zip(dict_key,[np.round(i,3) for i in dict_values]))\n",
    "\n",
    "def knn_classifier(bunchobject, feature_list, size, seed , k ): \n",
    "    data = bunchobject.data[:, feature_list]\n",
    "    target = bunchobject.target\n",
    "    data = normalize_minmax(data)\n",
    "    target = normalize_minmax(target)\n",
    "    data_train, data_test, target_train, target_test = train_test_split(data , target , test_size = size, random_state = seed )\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "    clf.fit(data_train, target_train)\n",
    "    target_predicted = clf.predict(data_test)\n",
    "    return get_metrics(target_test, target_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CS5 LINEAR REGRESSION ##\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "import numpy as np\n",
    "bunchobject= datasets.load_breast_cancer()\n",
    "\n",
    "def linear_regression(bunchobject, x_index, y_index, size, seed):\n",
    "    x = bunchobject.data[:,x_index]\n",
    "    y = bunchobject.data[:,y_index]\n",
    "    x_train, x_test, y_train, y_test = train_test_split( x , y , test_size= size, random_state = seed )\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x_train[:, None], y_train[:, None])\n",
    "    y_pred = regr.predict(x_test[:, None])\n",
    "    dict_key = ['coefficients','intercept','mean squared error','r2 score']\n",
    "    dict_values = [regr.coef_,regr.intercept_,mean_squared_error(y_test[:, None],y_pred),r2_score(y_test[:, None],y_pred)]\n",
    "    return x_train[:, None], y_train[:, None], x_test[:, None], y_pred, dict(zip(dict_key,dict_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CS6 MULTIPLE LINEAR REGRESSION ##\n",
    "from sklearn import linear_model, datasets\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import numpy as np\n",
    "bunchobject= datasets.load_breast_cancer()\n",
    "\n",
    "def multiple_linear_regression(bunchobject, x_index, y_index, order, size, seed):\n",
    "    x = bunchobject.data[:,np.newaxis,x_index]\n",
    "    y = bunchobject.data[:,np.newaxis,y_index]\n",
    "    poly = PolynomialFeatures(order,include_bias=False)\n",
    "    c = poly.fit_transform(x)\n",
    "    x_train, x_test, y_train, y_test = train_test_split( c , y , test_size= size, random_state = seed )\n",
    "    regr = linear_model.LinearRegression()\n",
    "    regr.fit(x_train, y_train)\n",
    "    y_pred = regr.predict(x_test)\n",
    "    dict_key = ['coefficients','intercept','mean squared error','r2 score']\n",
    "    dict_values = [regr.coef_,regr.intercept_,mean_squared_error(y_test,y_pred),r2_score(y_test,y_pred)]\n",
    "    return x_train[:,0], y_train, x_test[:,0], y_pred, dict(zip(dict_key,dict_values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## CS7 KNN FULL ##\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn import neighbors, datasets\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import numpy as np\n",
    "import sklearn.preprocessing as pp\n",
    "bunchobject= datasets.load_breast_cancer()\n",
    "\n",
    "normalize_minmax = lambda data: pp.minmax_scale(data)  \n",
    "\n",
    "def get_metrics(actual_targets, predicted_targets):\n",
    " c_matrix = confusion_matrix(actual_targets, predicted_targets)\n",
    " T_rec = np.sum(c_matrix)\n",
    " acc = np.trace(c_matrix)/T_rec\n",
    " sen = c_matrix[1][1]/np.sum(c_matrix[1])\n",
    " fp = c_matrix[0][1]/np.sum(c_matrix[0])\n",
    " dict_key = ['confusion matrix','total records','accuracy','sensitivity','false positive rate']\n",
    " dict_values = [c_matrix,T_rec,acc,sen,fp]\n",
    " return dict(zip(dict_key,[np.round(i,3) for i in dict_values]))\n",
    "\n",
    "def acc(a,b):\n",
    "    c_matrix = confusion_matrix(a, b)\n",
    "    T_rec = np.sum(c_matrix)\n",
    "    acc = np.trace(c_matrix)/T_rec\n",
    "    return acc\n",
    "\n",
    "def knn_classifier_full(bunchobject, feature_list, size, seed): \n",
    "    data = bunchobject.data[:, feature_list]\n",
    "    target = bunchobject.target\n",
    "    data = normalize_minmax(data)\n",
    "    target = normalize_minmax(target)\n",
    "    data_train, data_part2, target_train, target_part2 = train_test_split(data , target , test_size = size, random_state = seed )\n",
    "    data_valid, data_test, target_valid, target_test = train_test_split(data_part2 , target_part2 , test_size = 0.5, random_state = seed )\n",
    "    acc_list =[]\n",
    "    val_list = []\n",
    "    for k in range(1,20):\n",
    "     clf = neighbors.KNeighborsClassifier(n_neighbors=k)\n",
    "     clf.fit(data_train, target_train)\n",
    "     target_predicted = clf.predict(data_valid)\n",
    "     acc_list.append(acc(target_valid, target_predicted))\n",
    "     val_list.append((target_valid, target_predicted))   \n",
    "    K = acc_list.index(np.max(acc_list))+1\n",
    "    clf = neighbors.KNeighborsClassifier(n_neighbors=K)\n",
    "    clf.fit(data_train, target_train)\n",
    "    target_predicted = clf.predict(data_test)   \n",
    "    val, val_pred = val_list[K-1]\n",
    "    return {'best k':K, 'validation set': get_metrics(val,val_pred) , 'test set':  get_metrics(target_test, target_predicted)}            "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
